{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5bd948e-9560-4ab2-b5aa-c7d06ca3fa04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/07/26 14:19:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 94\u001b[0m\n\u001b[1;32m     92\u001b[0m         result \u001b[38;5;241m=\u001b[39m apply_rule(df, rule, column_name\u001b[38;5;241m=\u001b[39mrule[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 94\u001b[0m         result \u001b[38;5;241m=\u001b[39m apply_rule(\u001b[43mdf\u001b[49m, rule, column_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEntire DataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     95\u001b[0m     results_list\u001b[38;5;241m.\u001b[39mappend((rule[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m], result))\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# Print the results list\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/07/26 14:19:47 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, avg, sum, count, max, min\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Applying Rules to PySpark DataFrame\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Assuming you have already loaded your data into the DataFrame 'df'\n",
    "# Let's define your DataFrame 'df'\n",
    "\n",
    "# List of dictionaries representing the rules and their corresponding columns\n",
    "rules = [\n",
    "    {\n",
    "        \"name\": \"Total Row Count\",\n",
    "        \"description\": \"Calculate the total count of rows in the DataFrame.\",\n",
    "        \"function\": \"count\",\n",
    "        \"column\": None,\n",
    "        \"length\": None\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Average Length of Column1\",\n",
    "        \"description\": \"Calculate the average length of values in Column1.\",\n",
    "        \"function\": \"avg\",\n",
    "        \"column\": \"Column1\",\n",
    "        \"length\": None\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Percentage of Null Values in Column2\",\n",
    "        \"description\": \"Calculate the percentage of null values in Column2.\",\n",
    "        \"function\": \"sum\",\n",
    "        \"column\": \"Column2\",\n",
    "        \"length\": 0\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Percentage of Values with Specific Length in Column3\",\n",
    "        \"description\": \"Calculate the percentage of values with length 3 in Column3.\",\n",
    "        \"function\": \"count\",\n",
    "        \"column\": \"Column3\",\n",
    "        \"length\": 3\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Maximum Length in Column4\",\n",
    "        \"description\": \"Find the maximum length of values in Column4.\",\n",
    "        \"function\": \"max\",\n",
    "        \"column\": \"Column4\",\n",
    "        \"length\": None\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Minimum Length in Column5\",\n",
    "        \"description\": \"Find the minimum length of values in Column5.\",\n",
    "        \"function\": \"min\",\n",
    "        \"column\": \"Column5\",\n",
    "        \"length\": None\n",
    "    }\n",
    "]\n",
    "\n",
    "# Function to apply a rule to the DataFrame and return the result\n",
    "def apply_rule(df, rule, column_name):\n",
    "    func = rule[\"function\"]\n",
    "    col_name = rule[\"column\"]\n",
    "    length = rule[\"length\"]\n",
    "\n",
    "    if func == \"count\":\n",
    "        if col_name is None:\n",
    "            result = df.count()\n",
    "        elif length is not None:\n",
    "            result = df.filter((col(col_name).isNotNull()) & (length(col(col_name)) == length)).count()\n",
    "        else:\n",
    "            result = df.filter(col(col_name).isNotNull()).count()\n",
    "\n",
    "    elif func == \"avg\":\n",
    "        result = df.select(avg(length(col(col_name)))).first()[0]\n",
    "\n",
    "    elif func == \"sum\":\n",
    "        result = df.filter(length(col(col_name)) == length).count()\n",
    "        total_count = df.filter(col(col_name).isNotNull()).count()\n",
    "        result = (result * 100.0) / total_count if total_count > 0 else 0.0\n",
    "\n",
    "    elif func == \"max\":\n",
    "        result = df.select(max(length(col(col_name)))).first()[0]\n",
    "\n",
    "    elif func == \"min\":\n",
    "        result = df.select(min(length(col(col_name)))).first()[0]\n",
    "\n",
    "    return result\n",
    "\n",
    "# Calculate the percentage of rows that meet each rule and append them to a list\n",
    "results_list = []\n",
    "for rule in rules:\n",
    "    if rule[\"column\"] is not None:\n",
    "        result = apply_rule(df, rule, column_name=rule[\"column\"])\n",
    "    else:\n",
    "        result = apply_rule(df, rule, column_name=\"Entire DataFrame\")\n",
    "    results_list.append((rule[\"name\"], result))\n",
    "\n",
    "# Print the results list\n",
    "print(results_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af90a39d-fab0-48a9-a2e7-2646e2cd1801",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
